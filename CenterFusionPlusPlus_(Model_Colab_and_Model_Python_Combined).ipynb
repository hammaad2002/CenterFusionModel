{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN60OmMHOaLPrs53xQ1VR8d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hammaad2002/CenterFusionModel/blob/main/CenterFusionPlusPlus_(Model_Colab_and_Model_Python_Combined).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Following are steps to get Pytorch model in your current (colab) environment**"
      ],
      "metadata": {
        "id": "htg2JUdbfjXC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nm-cjio9eZRd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone --recursive https://github.com/brandesjj/centerfusionpp\n",
        "!pip install torch torchvision torchaudio nuscenes-devkit onnx progress\n",
        "%cd /content/centerfusionpp/src/lib/model/networks\n",
        "!git clone https://github.com/jinfagang/DCNv2_latest\n",
        "#After this step rename the folder 'DCNv2_latest' to just 'DCNv2'\n",
        "!mv /content/centerfusionpp/src/lib/model/networks/DCNv2_latest /content/centerfusionpp/src/lib/model/networks/DCNv2\n",
        "# bulding DCNv2 model\n",
        "%cd /content/centerfusionpp/src/lib/model/networks/DCNv2\n",
        "! ./make.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1) /content/centerfusionpp/src/lib/model/networks/base_model.py\n",
        "\n",
        "```\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "try:\n",
        "  from ..utils import _topk, _tranpose_and_gather_feat\n",
        "  from centerfusionpp.src.lib.utils.pointcloud import generate_pc_box_hm\n",
        "  from centerfusionpp.src.lib.utils.ddd_utils import project_to_image_torch\n",
        "  from centerfusionpp.src.lib.model.networks.lfanet import LFANet, MapChannels\n",
        "  import torch\n",
        "  from torch import nn\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "except:\n",
        "  from ..utils import _topk, _tranpose_and_gather_feat\n",
        "  from utils.pointcloud import generate_pc_box_hm\n",
        "  from utils.ddd_utils import project_to_image_torch\n",
        "  from model.networks.lfanet import LFANet, MapChannels\n",
        "  import torch\n",
        "  from torch import nn\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "```\n",
        "\n",
        "2) /content/centerfusionpp/src/lib/utils/pointcloud.py\n",
        "\n",
        "```\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "try:\n",
        "  from os import device_encoding\n",
        "  from turtle import color, pos\n",
        "  from matplotlib.colors import rgb2hex\n",
        "  from nuscenes.utils.data_classes import RadarPointCloud\n",
        "  from nuscenes.utils.geometry_utils import view_points, transform_matrix\n",
        "  from nuscenes.utils.data_classes import RadarPointCloud\n",
        "  from functools import reduce\n",
        "  from typing import Tuple, Dict\n",
        "  from centerfusionpp.src.lib.model.utils import _nms, _sigmoid, _topk, _tranpose_and_gather_feat\n",
        "  import os.path as osp\n",
        "  import torch\n",
        "  from typing import Tuple, List, Dict\n",
        "  import timeit\n",
        "  import matplotlib.pyplot as plt\n",
        "  import numpy as np\n",
        "  from pyquaternion import Quaternion\n",
        "  import copy\n",
        "  from centerfusionpp.src.lib.utils.eval_frustum import EvalFrustum\n",
        "  from centerfusionpp.src.lib.utils.ddd_utils import compute_corners_3d, compute_corners_3d_torch, alpha2rot_y, alpha2rot_y_torch, \\\n",
        "                              compute_box_3d, unproject_2d_to_3d_torch, compute_box_3d_torch\n",
        "  from centerfusionpp.src.lib.utils.image import transform_preds_with_trans_torch\n",
        "except:\n",
        "  from os import device_encoding\n",
        "  from turtle import color, pos\n",
        "  from matplotlib.colors import rgb2hex\n",
        "  from nuscenes.utils.data_classes import RadarPointCloud\n",
        "  from nuscenes.utils.geometry_utils import view_points, transform_matrix\n",
        "  from nuscenes.utils.data_classes import RadarPointCloud\n",
        "  from functools import reduce\n",
        "  from typing import Tuple, Dict\n",
        "  from model.utils import _nms, _sigmoid, _topk, _tranpose_and_gather_feat\n",
        "  import os.path as osp\n",
        "  import torch\n",
        "  from typing import Tuple, List, Dict\n",
        "  import timeit\n",
        "  import matplotlib.pyplot as plt\n",
        "  import numpy as np\n",
        "  from pyquaternion import Quaternion\n",
        "  import copy\n",
        "  from utils.eval_frustum import EvalFrustum\n",
        "  from utils.ddd_utils import compute_corners_3d, compute_corners_3d_torch, alpha2rot_y, alpha2rot_y_torch, \\\n",
        "                              compute_box_3d, unproject_2d_to_3d_torch, compute_box_3d_torch\n",
        "  from utils.image import transform_preds_with_trans_torch\n",
        "```\n",
        "\n",
        "3) /content/centerfusionpp/src/lib/utils/eval_frustum.py\n",
        "\n",
        "```\n",
        "try:\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib\n",
        "  import pickle # Used to dump list\n",
        "  from matplotlib.colors import Normalize\n",
        "  from typing import Tuple, List, Dict\n",
        "  import os\n",
        "  from random import randrange\n",
        "  import time\n",
        "  from centerfusionpp.src.lib.utils.ddd_utils import compute_box_3d, vgt_to_vrad, calc_frustum_corners\n",
        "  import copy\n",
        "except:\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib\n",
        "  import pickle # Used to dump list\n",
        "  from matplotlib.colors import Normalize\n",
        "  from typing import Tuple, List, Dict\n",
        "  import os\n",
        "  from random import randrange\n",
        "  import time\n",
        "  from utils.ddd_utils import compute_box_3d, vgt_to_vrad, calc_frustum_corners\n",
        "  import copy\n",
        "```\n",
        "\n",
        "4) /content/centerfusionpp/src/lib/model/networks/lfanet.py\n",
        "\n",
        "```\n",
        "try:\n",
        "  import copy\n",
        "  import imp\n",
        "  from math import log\n",
        "  import numpy as np\n",
        "  from pyparsing import rest_of_line\n",
        "  import torch\n",
        "  from torch import nn\n",
        "  from torch.nn import Conv2d, Sequential, ReLU, MaxPool2d, BatchNorm2d, Linear\n",
        "  import os\n",
        "  import matplotlib.pyplot as plt\n",
        "  from centerfusionpp.src.lib.model.utils import _nms, _sigmoid, _topk, _tranpose_and_gather_feat\n",
        "  from centerfusionpp.src.lib.utils.ddd_utils import ddd2locrot, ddd2locrot_torch, v_to_vrad_torch\n",
        "  from centerfusionpp.src.lib.utils.image import get_affine_transform, transform_preds_with_trans_torch, transform_preds_with_trans_torch_minibatch\n",
        "  from centerfusionpp.src.lib.utils.pointcloud import get_alpha, get_dist_thresh, get_dist_thresh_torch\n",
        "  from centerfusionpp.src.lib.utils.eval_frustum import EvalFrustum, debug_lfa_frustum\n",
        "  from centerfusionpp.src.lib.utils.snapshot import generate_snap_BEV_torch, generate_snap_proj_torch\n",
        "  from centerfusionpp.src.lib.model.networks.pointnetpp import PointNetPP, get_loss\n",
        "  import cv2\n",
        "  try:\n",
        "      from .DCNv2.dcn_v2_onnx import DCN\n",
        "  except:\n",
        "      print('Import DCN in dla.py failed')\n",
        "      print(f'Current location is {os.getcwd()}')\n",
        "      DCN = None\n",
        "except:\n",
        "  import copy\n",
        "  import imp\n",
        "  from math import log\n",
        "  import numpy as np\n",
        "  from pyparsing import rest_of_line\n",
        "  import torch\n",
        "  from torch import nn\n",
        "  from torch.nn import Conv2d, Sequential, ReLU, MaxPool2d, BatchNorm2d, Linear\n",
        "  import os\n",
        "  import matplotlib.pyplot as plt\n",
        "  from model.utils import _nms, _sigmoid, _topk, _tranpose_and_gather_feat\n",
        "  from utils.ddd_utils import ddd2locrot, ddd2locrot_torch, v_to_vrad_torch\n",
        "  from utils.image import get_affine_transform, transform_preds_with_trans_torch, transform_preds_with_trans_torch_minibatch\n",
        "  from utils.pointcloud import get_alpha, get_dist_thresh, get_dist_thresh_torch\n",
        "  from utils.eval_frustum import EvalFrustum, debug_lfa_frustum\n",
        "  from utils.snapshot import generate_snap_BEV_torch, generate_snap_proj_torch\n",
        "  from model.networks.pointnetpp import PointNetPP, get_loss\n",
        "  import cv2\n",
        "  try:\n",
        "      from .DCNv2.dcn_v2 import DCN\n",
        "  except:\n",
        "      print('Import DCN in dla.py failed')\n",
        "      print(f'Current location is {os.getcwd()}')\n",
        "      DCN = None\n",
        "```\n",
        "\n",
        "5) /content/centerfusionpp/src/lib/utils/snapshot.py\n",
        "\n",
        "```\n",
        "try:\n",
        "  from math import log\n",
        "  import numpy as np\n",
        "  from pyparsing import rest_of_line\n",
        "  import torch\n",
        "  import matplotlib.pyplot as plt\n",
        "  import copy\n",
        "  from utils.ddd_utils import calc_frustum_corners_torch, calc_frustum_corners, compute_box_3d_torch, compute_box_3d, \\\n",
        "                        get_2d_rotation_matrix, get_2d_rotation_matrix_torch, project_to_image, project_to_image_torch\n",
        "except:\n",
        "  from math import log\n",
        "  import numpy as np\n",
        "  from pyparsing import rest_of_line\n",
        "  import torch\n",
        "  import matplotlib.pyplot as plt\n",
        "  import copy\n",
        "  from centerfusionpp.src.lib.utils.ddd_utils import calc_frustum_corners_torch, calc_frustum_corners, compute_box_3d_torch, compute_box_3d, \\\n",
        "                        get_2d_rotation_matrix, get_2d_rotation_matrix_torch, project_to_image, project_to_image_torch\n",
        "```\n",
        "\n",
        "6) /content/centerfusionpp/src/lib/model/networks/pointnetpp.py\n",
        "\n",
        "```\n",
        "try:\n",
        "  import torch.nn as nn\n",
        "  import torch.nn.functional as F\n",
        "  from centerfusionpp.src.lib.model.networks.pointnetpp_utils import PointNetSetAbstractionMsg, PointNetSetAbstraction\n",
        "except:\n",
        "  import torch.nn as nn\n",
        "  import torch.nn.functional as F\n",
        "  from model.networks.pointnetpp_utils import PointNetSetAbstractionMsg, PointNetSetAbstraction\n",
        "```\n",
        "\n",
        "7) /content/centerfusionpp/src/lib/dataset/generic_dataset.py\n",
        "\n",
        "```\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "try:\n",
        "  from os import device_encoding\n",
        "  from turtle import color, pos\n",
        "  from matplotlib.colors import rgb2hex\n",
        "  from nuscenes.utils.data_classes import RadarPointCloud\n",
        "  from nuscenes.utils.geometry_utils import view_points, transform_matrix\n",
        "  from nuscenes.utils.data_classes import RadarPointCloud\n",
        "  from functools import reduce\n",
        "  from typing import Tuple, Dict\n",
        "  from centerfusionpp.src.lib.model.utils import _nms, _sigmoid, _topk, _tranpose_and_gather_feat\n",
        "  import os.path as osp\n",
        "  import torch\n",
        "  from typing import Tuple, List, Dict\n",
        "  import timeit\n",
        "  import matplotlib.pyplot as plt\n",
        "  import numpy as np\n",
        "  from pyquaternion import Quaternion\n",
        "  import copy\n",
        "  from centerfusionpp.src.lib.utils.eval_frustum import EvalFrustum\n",
        "  from centerfusionpp.src.lib.utils.ddd_utils import compute_corners_3d, compute_corners_3d_torch, alpha2rot_y, alpha2rot_y_torch, \\\n",
        "                              compute_box_3d, unproject_2d_to_3d_torch, compute_box_3d_torch\n",
        "  from centerfusionpp.src.lib.utils.image import transform_preds_with_trans_torch\n",
        "  import torch.utils.data as data\n",
        "except:\n",
        "  from os import device_encoding\n",
        "  from turtle import color, pos\n",
        "  from matplotlib.colors import rgb2hex\n",
        "  from nuscenes.utils.data_classes import RadarPointCloud\n",
        "  from nuscenes.utils.geometry_utils import view_points, transform_matrix\n",
        "  from nuscenes.utils.data_classes import RadarPointCloud\n",
        "  from functools import reduce\n",
        "  from typing import Tuple, Dict\n",
        "  from model.utils import _nms, _sigmoid, _topk, _tranpose_and_gather_feat\n",
        "  import os.path as osp\n",
        "  import torch\n",
        "  from typing import Tuple, List, Dict\n",
        "  import timeit\n",
        "  import matplotlib.pyplot as plt\n",
        "  import numpy as np\n",
        "  from pyquaternion import Quaternion\n",
        "  import copy\n",
        "  from utils.eval_frustum import EvalFrustum\n",
        "  from utils.ddd_utils import compute_corners_3d, compute_corners_3d_torch, alpha2rot_y, alpha2rot_y_torch, \\\n",
        "                              compute_box_3d, unproject_2d_to_3d_torch, compute_box_3d_torch\n",
        "  from utils.image import transform_preds_with_trans_torch\n",
        "  import torch.utils.data as data\n",
        "```\n",
        "\n",
        "8) /content/centerfusionpp/src/lib/dataset/datasets/kitti.py\n",
        "\n",
        "```\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "try:\n",
        "  import pycocotools.coco as coco\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  import json\n",
        "  import cv2\n",
        "  import os\n",
        "  import math\n",
        "  from ..generic_dataset import GenericDataset\n",
        "  from centerfusionpp.src.lib.utils.ddd_utils import compute_box_3d, project_to_image\n",
        "except:\n",
        "  import pycocotools.coco as coco\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  import json\n",
        "  import cv2\n",
        "  import os\n",
        "  import math\n",
        "  from ..generic_dataset import GenericDataset\n",
        "  from utils.ddd_utils import compute_box_3d, project_to_image\n",
        "```\n",
        "\n",
        "9) /content/centerfusionpp/src/lib/dataset/datasets/nuscenes.py\n",
        "\n",
        "```\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "try:\n",
        "  # Copyright (c) Xingyi Zhou. All Rights Reserved\n",
        "  import pycocotools.coco as coco\n",
        "  from pycocotools.cocoeval import COCOeval\n",
        "  from pyquaternion import Quaternion\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  import json\n",
        "  import cv2\n",
        "  import os\n",
        "  import math\n",
        "  import copy\n",
        "  from tqdm import tqdm\n",
        "  from ..generic_dataset import GenericDataset\n",
        "  from centerfusionpp.src.lib.utils.ddd_utils import compute_box_3d, project_to_image, iou3d_global\n",
        "  from nuscenes.utils.geometry_utils import view_points\n",
        "  from nuscenes.utils.data_classes import Box\n",
        "  from itertools import compress\n",
        "except:\n",
        "  # Copyright (c) Xingyi Zhou. All Rights Reserved\n",
        "  import pycocotools.coco as coco\n",
        "  from pycocotools.cocoeval import COCOeval\n",
        "  from pyquaternion import Quaternion\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  import json\n",
        "  import cv2\n",
        "  import os\n",
        "  import math\n",
        "  import copy\n",
        "  from tqdm import tqdm\n",
        "  from ..generic_dataset import GenericDataset\n",
        "  from utils.ddd_utils import compute_box_3d, project_to_image, iou3d_global\n",
        "  from nuscenes.utils.geometry_utils import view_points\n",
        "  from nuscenes.utils.data_classes import Box\n",
        "  from itertools import compress\n",
        "```\n",
        "\n",
        "10) /content/centerfusionpp/src/lib/dataset/datasets/kitti_tracking.py\n",
        "\n",
        "```\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "try:\n",
        "  import pycocotools.coco as coco\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  import json\n",
        "  import cv2\n",
        "  import os\n",
        "  import math\n",
        "  from ..generic_dataset import GenericDataset\n",
        "  from utils.ddd_utils import compute_box_3d, project_to_image\n",
        "except:\n",
        "  import pycocotools.coco as coco\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  import json\n",
        "  import cv2\n",
        "  import os\n",
        "  import math\n",
        "  from ..generic_dataset import GenericDataset\n",
        "  from centerfusionpp.src.lib.utils.ddd_utils import compute_box_3d, project_to_image\n",
        "```"
      ],
      "metadata": {
        "id": "htW8UYsmryQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from centerfusionpp.src.lib.opts import opts\n",
        "from centerfusionpp.src.lib.model.model import create_model, load_model\n",
        "from centerfusionpp.src.lib.dataset.dataset_factory import dataset_factory\n",
        "import torch\n",
        "\n",
        "opt = opts().parse(['ctdet'])\n",
        "opt.model_output_list = True\n",
        "Dataset = dataset_factory['nuscenes']\n",
        "opt = opts().update_dataset_info_and_set_heads(opt, Dataset)\n",
        "\n",
        "model = create_model(opt.arch, opt.heads, opt.head_conv, opt=opt)\n",
        "\n",
        "device = 'cpu'\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "dummy_input1 = torch.randn(1, 3, opt.input_h, opt.input_w).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6K9jzprsO0q",
        "outputId": "87e5beba-5d26-46e7-c577-4817a7acca7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fix size testing.\n",
            "Training chunk_sizes (master, slave1, slave2, ...):  [32]\n",
            "Input height: 448  & width:  800\n",
            "Heads:  {'hm': 10, 'reg': 2, 'wh': 2}\n",
            "Weights:  {'hm': 1, 'reg': 1, 'wh': 0.1}\n",
            "Convolutional setup per head:  {'hm': [256], 'reg': [256], 'wh': [256]}\n",
            "Using head kernel: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"http://dl.yf.io/dla/models/imagenet/dla34-ba72cf86.pth\" to /root/.cache/torch/hub/checkpoints/dla34-ba72cf86.pth\n",
            "100%|██████████| 60.3M/60.3M [00:10<00:00, 6.13MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DLA node type used for neck:  (<class 'centerfusionpp.src.lib.model.networks.dla.DeformConv'>, <class 'centerfusionpp.src.lib.model.networks.dla.DeformConv'>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Following are steps to convert Pytorch model to ONNX format**"
      ],
      "metadata": {
        "id": "_pRNAZl6hvk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3PwwY1ihupb",
        "outputId": "e0a811cd-8ddc-422c-e9db-e35217a4c6f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/centerfusionpp/src/convert_onnx.py\n",
        "\n",
        "```\n",
        "'''\n",
        "Script to convert a trained CenterNet model to ONNX, currently only\n",
        "support non-DCN models.\n",
        "'''\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import _init_paths\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from progress.bar import Bar\n",
        "import torch\n",
        "import copy\n",
        "\n",
        "from model.model import create_model, load_model\n",
        "from opts import opts\n",
        "from dataset.dataset_factory import dataset_factory\n",
        "from detector import Detector\n",
        "\n",
        "\n",
        "def convert_onnx(opt):\n",
        "\n",
        "  os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpus_str\n",
        "  opt.model_output_list = True\n",
        "\n",
        "  if opt.gpus[0] >= 0:\n",
        "    opt.device = torch.device('cuda')\n",
        "  else:\n",
        "    opt.device = torch.device('cpu')\n",
        "\n",
        "  Dataset = dataset_factory[opt.test_dataset]\n",
        "  opt = opts().update_dataset_info_and_set_heads(opt, Dataset)\n",
        "  model = create_model(\n",
        "      opt.arch, opt.heads, opt.head_conv, opt=opt)\n",
        "\n",
        "  if opt.load_model != '':\n",
        "    model = load_model(model, opt.load_model, opt)\n",
        "\n",
        "  opt.device = 'cpu'\n",
        "  model = model.to(opt.device)\n",
        "  model.eval()\n",
        "  dummy_input1 = torch.randn(1, 3, opt.input_h, opt.input_w).to(opt.device)\n",
        "  storing_path = '/content/onnx_models/'\n",
        "\n",
        "  if opt.tracking:\n",
        "    dummy_input2 = torch.randn(1, 3, opt.input_h, opt.input_w).to(opt.device)\n",
        "    \n",
        "    if opt.pre_hm:\n",
        "      dummy_input3 = torch.randn(1, 1, opt.input_h, opt.input_w).to(opt.device)\n",
        "      torch.onnx.export(\n",
        "        model, (dummy_input1, dummy_input2, dummy_input3),\n",
        "        \"../models/{}.onnx\".format(opt.exp_id))\n",
        "\n",
        "    else:\n",
        "      torch.onnx.export(\n",
        "        model, (dummy_input1, dummy_input2),\n",
        "        storing_path + opt.task + '.onnx')\n",
        "\n",
        "  else:\n",
        "    torch.onnx.export(\n",
        "    model, (dummy_input1, ),\n",
        "    storing_path + opt.task  + '.onnx',\n",
        "    opset_version=17,\n",
        "    custom_opsets={\"domain_version\": 17},\n",
        "    verbose=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  \n",
        "  opt = opts().parse()\n",
        "  convert_onnx(opt)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "/content/centerfusionpp/src/lib/model/networks/base_model.py file\n",
        "\n",
        "At line 202\n",
        "```\n",
        "      x = torch.cat((batch['image'], early_fusion_norm), 1)\n",
        "\n",
        "    else:    \n",
        "\n",
        "      x = batch\n",
        "```\n",
        "\n",
        "\n",
        "/content/centerfusionpp/src/lib/model/networks/DCNv2/dcn_v2_onnx.py\n",
        "```\n",
        "#!/usr/bin/env python\n",
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Function\n",
        "from torch.nn.modules.utils import _pair\n",
        "from torch.autograd.function import once_differentiable\n",
        "import json\n",
        "\n",
        "import _ext as _backend\n",
        "from torch.onnx import register_custom_op_symbolic\n",
        "\n",
        "# Define the custom operator registration function\n",
        "def my_custom_op(g, input, offset_mask, weight, bias, stride, padding, dilation, deformable_groups):\n",
        "    # This should match the definition in the symbolic method of your custom operator class.\n",
        "    return g.op(\"domain_version::Plugin\", input, offset_mask, weight, bias,\n",
        "                stride_s=stride, padding_s=padding, dilation_s=dilation, deformable_groups_i=deformable_groups)\n",
        "\n",
        "\n",
        "class _DCNv2(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def symbolic(g, input, offset_mask, weight, bias, stride, padding, dilation, deformable_groups):\n",
        "        return g.op(\"domain_version::Plugin\", input, offset_mask, weight, bias, name_s=\"DCNv2\", info_s=json.dumps({\n",
        "            \"dilation\": dilation,\n",
        "            \"padding\": padding,\n",
        "            \"stride\": stride,\n",
        "            \"deformable_groups\": deformable_groups\n",
        "        }))\n",
        "\n",
        "    ###############################################  修改的部分 ############################################################\n",
        "    # 这里以下的修改，并不是必须的，仅仅是复现DCN的时候，输入改成是input和offset_mask，原始的做法是chunk分割为x, y, mask，\n",
        "    # 然后再cat，再对mask做sigmoid后输入到dcn。这么做效率比较底下。实现DCN的时候输入input和offset_mask，内部做了分割和sigmomid\n",
        "    # 减少数据流转，提高效率，也因此在这里对操作做了修改\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, offset_mask, weight, bias,\n",
        "                stride, padding, dilation, deformable_groups):\n",
        "        ctx.stride = _pair(stride)\n",
        "        ctx.padding = _pair(padding)\n",
        "        ctx.dilation = _pair(dilation)\n",
        "        ctx.kernel_size = _pair(weight.shape[2:4])\n",
        "        ctx.deformable_groups = deformable_groups\n",
        "\n",
        "        o1, o2, mask = torch.chunk(offset_mask, 3, dim=1)\n",
        "        offset = torch.cat((o1, o2), dim=1)\n",
        "        mask = torch.sigmoid(mask)\n",
        "\n",
        "    # @staticmethod\n",
        "    # def forward(ctx, input, offset, mask, weight, bias,\n",
        "    #             stride, padding, dilation, deformable_groups):\n",
        "    #     ctx.stride = _pair(stride)\n",
        "    #     ctx.padding = _pair(padding)\n",
        "    #     ctx.dilation = _pair(dilation)\n",
        "    #     ctx.kernel_size = _pair(weight.shape[2:4])\n",
        "    #     ctx.deformable_groups = deformable_groups\n",
        "        output = _backend.dcn_v2_forward(input, weight, bias,\n",
        "                                         offset, mask,\n",
        "                                         ctx.kernel_size[0], ctx.kernel_size[1],\n",
        "                                         ctx.stride[0], ctx.stride[1],\n",
        "                                         ctx.padding[0], ctx.padding[1],\n",
        "                                         ctx.dilation[0], ctx.dilation[1],\n",
        "                                         ctx.deformable_groups)\n",
        "        ctx.save_for_backward(input, offset, mask, weight, bias)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    @once_differentiable\n",
        "    def backward(ctx, grad_output):\n",
        "        input, offset, mask, weight, bias = ctx.saved_tensors\n",
        "        grad_input, grad_offset, grad_mask, grad_weight, grad_bias = \\\n",
        "            _backend.dcn_v2_backward(input, weight,\n",
        "                                     bias,\n",
        "                                     offset, mask,\n",
        "                                     grad_output,\n",
        "                                     ctx.kernel_size[0], ctx.kernel_size[1],\n",
        "                                     ctx.stride[0], ctx.stride[1],\n",
        "                                     ctx.padding[0], ctx.padding[1],\n",
        "                                     ctx.dilation[0], ctx.dilation[1],\n",
        "                                     ctx.deformable_groups)\n",
        "\n",
        "        return grad_input, grad_offset, grad_mask, grad_weight, grad_bias,\\\n",
        "            None, None, None, None,\n",
        "\n",
        "\n",
        "dcn_v2_conv = _DCNv2.apply\n",
        "\n",
        "\n",
        "class DCNv2(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels,\n",
        "                 kernel_size, stride=1, padding=1, dilation=1, deformable_groups=1):\n",
        "        super(DCNv2, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = _pair(kernel_size)\n",
        "        self.stride = _pair(stride)\n",
        "        self.padding = _pair(padding)\n",
        "        self.dilation = _pair(dilation)\n",
        "        self.deformable_groups = deformable_groups\n",
        "\n",
        "        self.weight = nn.Parameter(torch.Tensor(\n",
        "            out_channels, in_channels, *self.kernel_size))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "        # Register the custom operator with a unique domain name.\n",
        "        register_custom_op_symbolic('domain_version::Plugin', my_custom_op, 17)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        n = self.in_channels\n",
        "        for k in self.kernel_size:\n",
        "            n *= k\n",
        "        stdv = 1. / math.sqrt(n)\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input, offset, mask):\n",
        "        assert 2 * self.deformable_groups * self.kernel_size[0] * self.kernel_size[1] == \\\n",
        "            offset.shape[1]\n",
        "        assert self.deformable_groups * self.kernel_size[0] * self.kernel_size[1] == \\\n",
        "            mask.shape[1]\n",
        "        return dcn_v2_conv(input, offset, mask,\n",
        "                           self.weight,\n",
        "                           self.bias,\n",
        "                           self.stride,\n",
        "                           self.padding,\n",
        "                           self.dilation,\n",
        "                           self.deformable_groups)\n",
        "\n",
        "\n",
        "class DCN(DCNv2):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels,\n",
        "                 kernel_size, stride, padding,\n",
        "                 dilation=1, deformable_groups=1):\n",
        "        super(DCN, self).__init__(in_channels, out_channels,\n",
        "                                  kernel_size, stride, padding, dilation, deformable_groups)\n",
        "\n",
        "        channels_ = self.deformable_groups * 3 * self.kernel_size[0] * self.kernel_size[1]\n",
        "        self.conv_offset_mask = nn.Conv2d(self.in_channels,\n",
        "                                          channels_,\n",
        "                                          kernel_size=self.kernel_size,\n",
        "                                          stride=self.stride,\n",
        "                                          padding=self.padding,\n",
        "                                          bias=True)\n",
        "        self.init_offset()\n",
        "        # Register the custom operator with a unique domain name.\n",
        "        register_custom_op_symbolic('domain_version::Plugin', my_custom_op, 17)\n",
        "\n",
        "    def init_offset(self):\n",
        "        self.conv_offset_mask.weight.data.zero_()\n",
        "        self.conv_offset_mask.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "        # out = self.conv_offset_mask(input)\n",
        "        # o1, o2, mask = torch.chunk(out, 3, dim=1)\n",
        "        # offset = torch.cat((o1, o2), dim=1)\n",
        "        # mask = torch.sigmoid(mask)\n",
        "        # return dcn_v2_conv(input, offset, mask,\n",
        "        #                    self.weight, self.bias,\n",
        "        #                    self.stride,\n",
        "        #                    self.padding,\n",
        "        #                    self.dilation,\n",
        "        #                    self.deformable_groups)\n",
        "        \n",
        "        ###############################################  修改的部分 ############################################################\n",
        "        offset_mask = self.conv_offset_mask(input)\n",
        "        #o1, o2, mask = torch.chunk(out, 3, dim=1)\n",
        "        #offset = torch.cat((o1, o2), dim=1)\n",
        "        #mask = torch.sigmoid(mask)\n",
        "        return dcn_v2_conv(input, offset_mask,\n",
        "                           self.weight, self.bias,\n",
        "                           self.stride,\n",
        "                           self.padding,\n",
        "                           self.dilation,\n",
        "                           self.deformable_groups)\n",
        "        ###############################################  ---------- ############################################################\n",
        "\n",
        "\n",
        "\n",
        "class _DCNv2Pooling(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, rois, offset,\n",
        "                spatial_scale,\n",
        "                pooled_size,\n",
        "                output_dim,\n",
        "                no_trans,\n",
        "                group_size=1,\n",
        "                part_size=None,\n",
        "                sample_per_part=4,\n",
        "                trans_std=.0):\n",
        "        ctx.spatial_scale = spatial_scale\n",
        "        ctx.no_trans = int(no_trans)\n",
        "        ctx.output_dim = output_dim\n",
        "        ctx.group_size = group_size\n",
        "        ctx.pooled_size = pooled_size\n",
        "        ctx.part_size = pooled_size if part_size is None else part_size\n",
        "        ctx.sample_per_part = sample_per_part\n",
        "        ctx.trans_std = trans_std\n",
        "\n",
        "        output, output_count = \\\n",
        "            _backend.dcn_v2_psroi_pooling_forward(input, rois, offset,\n",
        "                                                  ctx.no_trans, ctx.spatial_scale,\n",
        "                                                  ctx.output_dim, ctx.group_size,\n",
        "                                                  ctx.pooled_size, ctx.part_size,\n",
        "                                                  ctx.sample_per_part, ctx.trans_std)\n",
        "        ctx.save_for_backward(input, rois, offset, output_count)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    @once_differentiable\n",
        "    def backward(ctx, grad_output):\n",
        "        input, rois, offset, output_count = ctx.saved_tensors\n",
        "        grad_input, grad_offset = \\\n",
        "            _backend.dcn_v2_psroi_pooling_backward(grad_output,\n",
        "                                                   input,\n",
        "                                                   rois,\n",
        "                                                   offset,\n",
        "                                                   output_count,\n",
        "                                                   ctx.no_trans,\n",
        "                                                   ctx.spatial_scale,\n",
        "                                                   ctx.output_dim,\n",
        "                                                   ctx.group_size,\n",
        "                                                   ctx.pooled_size,\n",
        "                                                   ctx.part_size,\n",
        "                                                   ctx.sample_per_part,\n",
        "                                                   ctx.trans_std)\n",
        "\n",
        "        return grad_input, None, grad_offset, \\\n",
        "            None, None, None, None, None, None, None, None\n",
        "\n",
        "\n",
        "dcn_v2_pooling = _DCNv2Pooling.apply\n",
        "\n",
        "\n",
        "class DCNv2Pooling(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 spatial_scale,\n",
        "                 pooled_size,\n",
        "                 output_dim,\n",
        "                 no_trans,\n",
        "                 group_size=1,\n",
        "                 part_size=None,\n",
        "                 sample_per_part=4,\n",
        "                 trans_std=.0):\n",
        "        super(DCNv2Pooling, self).__init__()\n",
        "        self.spatial_scale = spatial_scale\n",
        "        self.pooled_size = pooled_size\n",
        "        self.output_dim = output_dim\n",
        "        self.no_trans = no_trans\n",
        "        self.group_size = group_size\n",
        "        self.part_size = pooled_size if part_size is None else part_size\n",
        "        self.sample_per_part = sample_per_part\n",
        "        self.trans_std = trans_std\n",
        "\n",
        "    def forward(self, input, rois, offset):\n",
        "        assert input.shape[1] == self.output_dim\n",
        "        if self.no_trans:\n",
        "            offset = input.new()\n",
        "        return dcn_v2_pooling(input, rois, offset,\n",
        "                              self.spatial_scale,\n",
        "                              self.pooled_size,\n",
        "                              self.output_dim,\n",
        "                              self.no_trans,\n",
        "                              self.group_size,\n",
        "                              self.part_size,\n",
        "                              self.sample_per_part,\n",
        "                              self.trans_std)\n",
        "\n",
        "\n",
        "class DCNPooling(DCNv2Pooling):\n",
        "\n",
        "    def __init__(self,\n",
        "                 spatial_scale,\n",
        "                 pooled_size,\n",
        "                 output_dim,\n",
        "                 no_trans,\n",
        "                 group_size=1,\n",
        "                 part_size=None,\n",
        "                 sample_per_part=4,\n",
        "                 trans_std=.0,\n",
        "                 deform_fc_dim=1024):\n",
        "        super(DCNPooling, self).__init__(spatial_scale,\n",
        "                                         pooled_size,\n",
        "                                         output_dim,\n",
        "                                         no_trans,\n",
        "                                         group_size,\n",
        "                                         part_size,\n",
        "                                         sample_per_part,\n",
        "                                         trans_std)\n",
        "\n",
        "        self.deform_fc_dim = deform_fc_dim\n",
        "\n",
        "        if not no_trans:\n",
        "            self.offset_mask_fc = nn.Sequential(\n",
        "                nn.Linear(self.pooled_size * self.pooled_size *\n",
        "                          self.output_dim, self.deform_fc_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(self.deform_fc_dim, self.deform_fc_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(self.deform_fc_dim, self.pooled_size *\n",
        "                          self.pooled_size * 3)\n",
        "            )\n",
        "            self.offset_mask_fc[4].weight.data.zero_()\n",
        "            self.offset_mask_fc[4].bias.data.zero_()\n",
        "\n",
        "    def forward(self, input, rois):\n",
        "        offset = input.new()\n",
        "\n",
        "        if not self.no_trans:\n",
        "\n",
        "            # do roi_align first\n",
        "            n = rois.shape[0]\n",
        "            roi = dcn_v2_pooling(input, rois, offset,\n",
        "                                 self.spatial_scale,\n",
        "                                 self.pooled_size,\n",
        "                                 self.output_dim,\n",
        "                                 True,  # no trans\n",
        "                                 self.group_size,\n",
        "                                 self.part_size,\n",
        "                                 self.sample_per_part,\n",
        "                                 self.trans_std)\n",
        "\n",
        "            # build mask and offset\n",
        "            offset_mask = self.offset_mask_fc(roi.view(n, -1))\n",
        "            offset_mask = offset_mask.view(\n",
        "                n, 3, self.pooled_size, self.pooled_size)\n",
        "            o1, o2, mask = torch.chunk(offset_mask, 3, dim=1)\n",
        "            offset = torch.cat((o1, o2), dim=1)\n",
        "            mask = torch.sigmoid(mask)\n",
        "\n",
        "            # do pooling with offset and mask\n",
        "            return dcn_v2_pooling(input, rois, offset,\n",
        "                                  self.spatial_scale,\n",
        "                                  self.pooled_size,\n",
        "                                  self.output_dim,\n",
        "                                  self.no_trans,\n",
        "                                  self.group_size,\n",
        "                                  self.part_size,\n",
        "                                  self.sample_per_part,\n",
        "                                  self.trans_std) * mask\n",
        "        # only roi_align\n",
        "        return dcn_v2_pooling(input, rois, offset,\n",
        "                              self.spatial_scale,\n",
        "                              self.pooled_size,\n",
        "                              self.output_dim,\n",
        "                              self.no_trans,\n",
        "                              self.group_size,\n",
        "                              self.part_size,\n",
        "                              self.sample_per_part,\n",
        "                              self.trans_std)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "j_CwTNzch2zX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/onnx_models/"
      ],
      "metadata": {
        "id": "EoHv6qfqiJ4T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) /content/centerfusionpp/src/lib/model/networks/dla.py\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import math\n",
        "import logging\n",
        "import numpy as np\n",
        "from os.path import join\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "from .base_model import BaseModel\n",
        "\n",
        "try:\n",
        "    # from .DCNv2.dcn_v2 import DCN\n",
        "    from .DCNv2.dcn_v2_onnx import DCN\n",
        "    print('Imported DCN inside dla.py file successfully.')\n",
        "except:\n",
        "    print('Import DCN in dla.py failed')\n",
        "    print(f'Current location is {os.getcwd()}')\n",
        "    DCN = None\n",
        "```\n",
        "\n",
        "2) /content/centerfusionpp/src/lib/model/networks/resdcn.py\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# ------------------------------------------------------------------------------\n",
        "# Copyright (c) Microsoft\n",
        "# Licensed under the MIT License.\n",
        "# Written by Bin Xiao (Bin.Xiao@microsoft.com)\n",
        "# Modified by Dequan Wang and Xingyi Zhou\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import math\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "try:\n",
        "    # from .DCNv2.dcn_v2 import DCN\n",
        "    from .DCNv2.dcn_v2_onnx import DCN\n",
        "    print('Imported DCN inside resdcn.py file successfully.')\n",
        "#   from dcn_v2 import DCN\n",
        "#   from src.lib.model.networks.DCNv2.dcn_v2 import DCN\n",
        "except:\n",
        "  print('Import DCN failed')\n",
        "  DCN = None\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from .base_model import BaseModel\n",
        "```\n",
        "\n",
        "3) /content/centerfusionpp/src/lib/model/networks/necks/dlaup.py\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import math\n",
        "import logging\n",
        "import numpy as np\n",
        "from os.path import join\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "try:\n",
        "    # from ..DCNv2.dcn_v2 import DCN\n",
        "    from ..DCNv2.dcn_v2_onnx import DCN\n",
        "    print('Imported DCN inside necks/dlaup.py file successfully.')\n",
        "except:\n",
        "  print('import DCN failed')\n",
        "  DCN = None\n",
        "```\n",
        "\n",
        "4) /content/centerfusionpp/src/lib/model/networks/necks/msraup.py\n",
        "\n",
        "\n",
        "```\n",
        "# ------------------------------------------------------------------------------\n",
        "# Copyright (c) Microsoft\n",
        "# Licensed under the MIT License.\n",
        "# Written by Bin Xiao (Bin.Xiao@microsoft.com)\n",
        "# Modified by Dequan Wang and Xingyi Zhou\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import math\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "try:\n",
        "    # from ..DCNv2.dcn_v2 import DCN\n",
        "    from ..DCNv2.dcn_v2_onnx import DCN\n",
        "    print('Imported DCN inside necks/msraup.py file successfully.')\n",
        "except:\n",
        "  print('import DCN failed')\n",
        "  DCN = None\n",
        "```"
      ],
      "metadata": {
        "id": "viwwM28iiOMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/centerfusionpp/src/convert_onnx.py ctdet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovAzuEaBikn-",
        "outputId": "a868df07-20d3-407f-9247-792761314c91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported DCN inside dla.py file successfully.\n",
            "Imported DCN inside resdcn.py file successfully.\n",
            "Imported DCN inside necks/dlaup.py file successfully.\n",
            "Imported DCN inside necks/msraup.py file successfully.\n",
            "Fix size testing.\n",
            "Training chunk_sizes (master, slave1, slave2, ...):  [32]\n",
            "Input height: 448  & width:  800\n",
            "Heads:  {'hm': 10, 'reg': 2, 'wh': 2}\n",
            "Weights:  {'hm': 1, 'reg': 1, 'wh': 0.1}\n",
            "Convolutional setup per head:  {'hm': [256], 'reg': [256], 'wh': [256]}\n",
            "Using head kernel: 3\n",
            "DLA node type used for neck:  (<class 'model.networks.dla.DeformConv'>, <class 'model.networks.dla.DeformConv'>)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
            "[W shape_type_inference.cpp:1974] Warning: The shape inference of domain_version::Plugin type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hOXdjlljsy5",
        "outputId": "c9a43fe5-ba52-4648-d4f7-43f3e7453f9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DLASeg(\n",
              "  (hm): Sequential(\n",
              "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (reg): Sequential(\n",
              "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (wh): Sequential(\n",
              "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (base): DLA(\n",
              "    (base_layer): Sequential(\n",
              "      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (level0): Sequential(\n",
              "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (level1): Sequential(\n",
              "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (level2): Tree(\n",
              "      (root): Root(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (tree1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (tree2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (level3): Tree(\n",
              "      (tree1): Tree(\n",
              "        (root): Root(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (tree1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (tree2): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (project): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (tree2): Tree(\n",
              "        (root): Root(\n",
              "          (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (tree1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (tree2): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (level4): Tree(\n",
              "      (tree1): Tree(\n",
              "        (root): Root(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (tree1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (tree2): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (project): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (tree2): Tree(\n",
              "        (root): Root(\n",
              "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (tree1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (tree2): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (level5): Tree(\n",
              "      (root): Root(\n",
              "        (conv): Conv2d(1280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (tree1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (tree2): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (fc): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (dla_up): DLAUp(\n",
              "    (ida_0): IDAUp(\n",
              "      (proj_1): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (up_1): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
              "      (node_1): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ida_1): IDAUp(\n",
              "      (proj_1): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (up_1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
              "      (node_1): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (proj_2): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (up_2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
              "      (node_2): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ida_2): IDAUp(\n",
              "      (proj_1): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "      (node_1): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (proj_2): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (up_2): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "      (node_2): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (proj_3): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (up_3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "      (node_3): DeformConv(\n",
              "        (conv): DCN(\n",
              "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (actf): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ida_up): IDAUp(\n",
              "    (proj_1): DeformConv(\n",
              "      (conv): DCN(\n",
              "        (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (actf): Sequential(\n",
              "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "    (node_1): DeformConv(\n",
              "      (conv): DCN(\n",
              "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (actf): Sequential(\n",
              "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (proj_2): DeformConv(\n",
              "      (conv): DCN(\n",
              "        (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (actf): Sequential(\n",
              "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (up_2): ConvTranspose2d(64, 64, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), groups=64, bias=False)\n",
              "    (node_2): DeformConv(\n",
              "      (conv): DCN(\n",
              "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (actf): Sequential(\n",
              "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install num2words"
      ],
      "metadata": {
        "id": "KU1F48r2kzYo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from num2words import num2words\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('Total number of parameters are almost equal to', num2words(total_params).split(' ')[0] + ' ' + num2words(total_params).split(' ')[1], 'or precisely equal to', total_params)\n",
        "print('And total number of trainable parameter are almost equal to', num2words(trainable_params).split(' ')[0] + ' ' + num2words(trainable_params).split(' ')[1], 'or precisely equal to', trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBcuiwiDkqR_",
        "outputId": "806a2222-0dfc-44ea-8d88-4dee3c81a3f1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters are almost equal to twenty million, or precisely equal to 20170902\n",
            "And total number of trainable parameter are almost equal to twenty million, or precisely equal to 20170902\n"
          ]
        }
      ]
    }
  ]
}